

### ğŸ“Œ **Modern README for Sign Language Recognition**

# ğŸ–ï¸ Sign Language Recognition
![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)
![Framework](https://img.shields.io/badge/Framework-PyTorch-orange.svg)
![Machine Learning](https://img.shields.io/badge/Machine%20Learning-XGBoost%20%7C%20Transformers-green)
![License](https://img.shields.io/badge/License-MIT-brightgreen)

ğŸš€ This repository contains code for **Sign Language Recognition**, developed as part of our **Final Year Project**.  
It uses **Mediapipe Hands**, **Blazepose**, and **Deep Learning Models (Transformers, LSTMs, XGBoost)** for accurate gesture recognition.

---

## ğŸ“– Table of Contents
- [ğŸ“‚ Dataset](#-dataset)
- [âš™ï¸ Installation](#ï¸-installation)
- [ğŸ’¡ Usage](#-usage)
- [ğŸ“Œ Training & Evaluation](#-training--evaluation)
- [ğŸ“Š Model Inference](#-model-inference)
- [ğŸ‘¤ Authors](#-authors)
- [ğŸ“œ License](#-license)

---

## ğŸ“‚ Dataset
The **INCLUDE 50 Dataset** is used for training and evaluation.  
ğŸ“¥ **[Download Here](https://zenodo.org/records/4010759)**  

---

## âš™ï¸ **Installation**

### **1ï¸âƒ£ Clone the Repository**
```bash
git clone https://github.com/yourusername/sign-language-recognition.git
cd sign-language-recognition
```

### **2ï¸âƒ£ Create a Virtual Environment (Recommended)**
```bash
python -m venv signlang_env
source signlang_env/bin/activate  # For Linux/Mac
signlang_env\Scripts\activate     # For Windows
```

### **3ï¸âƒ£ Install Dependencies**
```bash
pip install -r requirements.txt
```

---

## ğŸ’¡ **Usage**

### **ğŸ”¹ 1. Generate Keypoints**
Extract **Mediapipe Hands & Blazepose keypoints** from videos and save them.
```bash
python generate_keypoints.py --include_dir <path_to_dataset> --save_dir <path_to_save_keypoints> --dataset <include/include50>
```

---

## ğŸ“Œ **Training & Evaluation**
### **ğŸ”¹ 2. Train a Model**
Train a **Transformer / LSTM / XGBoost** model on the dataset.
```bash
python runner.py --dataset <include/include50> --use_augs --model transformer --data_dir <path_to_keypoints>
```

### **ğŸ”¹ 3. Resume Training or Evaluate a Pretrained Model**
Use a **pretrained model** for either evaluation or continuing training.
```bash
python runner.py --dataset <include/include50> --use_augs --model transformer --data_dir <path_to_keypoints> --use_pretrained <evaluate/resume_training>
```

---

## ğŸ“Š **Model Inference**
### **ğŸ”¹ 4. Get Predictions from a Pretrained Model**
Perform **sign language predictions** on new videos.
```bash
python evaluate.py --data_dir <path_to_videos>
```

---

## ğŸ‘¤ **Authors**
### **ğŸ“ Developed By**
<table>
  <tr>
    <td align="center">
      <a href="https://github.com/RohanPatil2">
        <img src="https://avatars.githubusercontent.com/u/12345678?v=4" width="100px;" alt="Rohan Patil"/>
        <br><b>Rohan Patil</b>
      </a>
      <br>
      <a href="https://github.com/RohanPatil2"><img src="https://img.shields.io/badge/GitHub-%40RohanPatil2-black.svg"></a>
    </td>
    <td align="center">
      <a href="https://github.com/sherurox">
        <img src="https://avatars.githubusercontent.com/u/87654321?v=4" width="100px;" alt="Shreyas Khandale"/>
        <br><b>Shreyas Khandale</b>
      </a>
      <br>
      <a href="https://github.com/sherurox"><img src="https://img.shields.io/badge/GitHub-%40sherurox-black.svg"></a>
    </td>
  </tr>
</table>

---

## ğŸ“œ **License**
This project is licensed under the **MIT License**.

---

## ğŸŒŸ **Support & Contributions**
If you find this project helpful, please **â­ï¸ star** this repository!  
Feel free to **fork** it and contribute via **Pull Requests**! ğŸš€

---
```

-
